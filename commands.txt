& "C:\Users\Daniel's laptop\AppData\Local\Programs\Python\Python312\python.exe" -m venv venv

.\venv\Scripts\activate

pip freeze | ForEach-Object { pip uninstall -y $_ }

pip install -r requirements.txt
pip install pandas --only-binary :all:

//download models to /scratch - probably overkill:
(venv) dt00561@heron179:~/fyp$ export HF_HOME="/scratch/dt00561/huggingface_cache"
(venv) dt00561@heron179:~/fyp$ echo $HF_HOME
/scratch/dt00561/huggingface_cache
(venv) dt00561@heron179:~/fyp$ mkdir -p $HF_HOME
(venv) dt00561@heron179:~/fyp$ echo $HF_HOME
/scratch/dt00561/huggingface_cache
(venv) dt00561@heron179:~/fyp$ nano ~/.bashrc
(venv) dt00561@heron179:~/fyp$ mkdir -p $HF_HOME




run mistral:
dt00561@otter04:/scratch/dt00561/ollama/bin$ ls
ollama  start_ollama_gpu.sh
dt00561@otter04:/scratch/dt00561/ollama/bin$ ./start_ollama_gpu.sh

start_ollama_gpu.sh:
#!/bin/bash
export OLLAMA_MODELS=/scratch/dt00561/ollama/models
OLLAMA_GPU_LAYERS=35 \  # Increased for A4000's 16GB VRAM
OLLAMA_FLASH_ATTENTION=1 \  # Enable optimized attention
CUDA_VISIBLE_DEVICES=0 \
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu:$LD_LIBRARY_PATH

# Create model directory if missing
mkdir -p "$OLLAMA_MODELS"

# Run from current directory
./ollama serve
